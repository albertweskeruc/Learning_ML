{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rodriguez_Abel_Lab1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps7fb67vFhTK"
      },
      "source": [
        "## **Exercise 1.** Write a function to compute the confusion matrix and use it to describe the results from the classification of the MNIST test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-8r6MWeHChp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44ee9a1f-4049-4469-b30a-dc4b87695b90"
      },
      "source": [
        "#The Code for the better way of doing everything from below, from reshape array to changing int type to float\n",
        "#saves 4 line of code. \n",
        "##x_train = np.float32(x_train/255).reshape(x_train.shape[0],-1)\n",
        "##x_test = np.float32(x_test/255).reshape(x_test.shape[0],-1)\n",
        "#########################################################################################################################################################\n",
        "#x_train = x_train.reshape(x_train.shape[0],-1)  #arrayName.reshape(size of 1st D, -1 to combine remaining 2nd&3rd dimension into 1)\n",
        "#x_test = x_test.reshape(x_test.shape[0],-1)\n",
        "#print(x_train.shape)                             #shows 2D array and the 2nd and 3rd column were multiplied together 28x28 = 784\n",
        "#x_train = x_train.astype(np.float32)/255                       #changes int type to float\n",
        "#x_test = x_test.astype(np.float32)/255\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = np.float32(x_train/255).reshape(x_train.shape[0],-1)\n",
        "x_test = np.float32(x_test/255).reshape(x_test.shape[0],-1)\n",
        "\n",
        "step = 5\n",
        "#python arrays do different functions with , and :\n",
        "x_train = x_train[::step] #arrayName[lowest limit: highest limit :increment by]\n",
        "y_train = y_train[::step] \n",
        "x_test = x_test[::step]\n",
        "y_test = y_test[::step]\n",
        "\n",
        "def distance(p,q): #Euclidean\n",
        "    return np.sqrt(np.sum(np.square(p-q))) \n",
        "\n",
        "def most_common(labels):\n",
        "    count = np.zeros(np.amax(labels)+1,dtype=np.int32)\n",
        "    for c in labels:\n",
        "        count[c] +=1\n",
        "    return np.argmax(count)\n",
        "\n",
        "def accuracy(p,y):\n",
        "    return np.mean(p==y)\n",
        "\n",
        "def knn(x_train, y_train, x_test, k):\n",
        "    predicted = np.zeros(x_test.shape[0],dtype=int)\n",
        "    d = np.zeros(x_train.shape[0],dtype=np.float32)\n",
        "    for i in range(x_test.shape[0]):\n",
        "        for j in range(x_train.shape[0]):\n",
        "            d[j] = distance(x_test[i],x_train[j]) \n",
        "        neighbors = np.argsort(d)[:k]\n",
        "        predicted[i] = most_common(y_train[neighbors])\n",
        "    return predicted\n",
        "\n",
        "def confusion_matrix(y_test, predicted):\n",
        "\n",
        "  c_matrix = np.zeros((np.amax(y_test)+1, np.amax(y_test)+1), dtype=int)\n",
        "  \n",
        "  for i in range(np.amax(y_test)+1):\n",
        "    for j in range(np.amax(y_test)+1):\n",
        "\n",
        "  return cm\n",
        "\n",
        "def confusion_matrix(y_test, predicted):\n",
        "\n",
        "                                                                   \n",
        "  print(pred) \n",
        "  print(y_test)                     \n",
        "  for i in range(len(y_test)): \n",
        "    for j in range(len(pred)): \n",
        "       if pred[j]==y_test[i]:\n",
        "         cm[y_test[i], pred[j]]+=1\n",
        "\n",
        "\n",
        "predicted = knn(x_train, y_train, x_test[:100], 5)\n",
        "print(confusion_matrix(y_test[:100], predicted)) \n",
        "print(accuracy(pred, y_test[:10]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 1 0 5 9 0 3 2 1 5 6 0 7 4 7 7 7 4 3 4 6 9 8 4 5 9 6 1 6 1 9 5 4 5 4 7 1\n",
            " 9 1 3 3 3 4 0 7 2 3 9 5 3 4 7 8 1 3 4 2 2 8 4 4 0 3 9 9 4 1 3 5 1 1 8 4 0\n",
            " 7 5 0 1 2 5 2 4 7 7 4 4 1 8 0 6 3 1 5 8 8 4 1 0 0 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRjI0a2eSIkc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhiDtIMW98E5"
      },
      "source": [
        "#Exercise 1 analysis:\n",
        "The defined method **confusion_matrix**, handles both the results contained in pred after implementing knn and the y_test. This is because confusion matrix is created by how many unique results are in the arrays. In this case we are expecting a 10 by 10 array because that is exact number of unique results/outputs because of how MNIST clusters by 10 continous classes from 0-9. \n",
        "\n",
        "For the second line of code, the assumption I am using to make the 10 by 10 array and about the MNIST y_test for the confusion matrix is that there is exactly 10 continuous classes from 0-9 and so we just have to get the max result/output and add by 1 since we know of class 9 and is represented as a 9.\n",
        "\n",
        "array size of y_test has to be big enough to ensure because 10  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7rWq9dfFmyI"
      },
      "source": [
        "## **Exercise 2**.Fashion MNIST is another simple and commonly used dataset to test machine learning algorithms.\n",
        "\n",
        "Display some randomly-chose images from Fashion-MNIST.\n",
        "Evaluate the accuracy of 3-nearest neighbor on Fashion-MNIST.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOLvgwSoY3HW"
      },
      "source": [
        "**Part 1 out of 2 for Exercise 2.** Display some randomly-chose images from Fashion-MNIST.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpDaLTTEHAKb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1919d4e0-dc99-4e49-8a8d-01c891c144ae"
      },
      "source": [
        "#Part 1 out of 2 for Exercise 2. Display some randomly-chose images from Fashion-MNIST.\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "print('Dataset sizes:')\n",
        "print(x_train.shape)  #arrayName.shape, the array is 3-D, (#of images, #of columns in each image, #of rows in each image)\n",
        "print(y_train.shape)  #1-D because it tells you what each image's result/classification/answer is\n",
        "\n",
        "print(x_test.shape)   #arrayName.shape, the array is 3-D, (#of images, #of columns in each image, #of rows in each image)\n",
        "print(y_test.shape)   #1-D because it tells you what each image's result/classification/answer is\n",
        "\n",
        "#prints 3 random images from the FASHION-MNIST Set\n",
        "for i in range(3):\n",
        "  im = np.random.randint(0,x_train.shape[0]) \n",
        "  plt.imshow(x_train[im],cmap='gray')\n",
        "  print('Class:',y_train[im]) #y_train holds the result/classification of the image\n",
        "  plt.show() #print grayscale image\n",
        "\n",
        "#this prints the numbers/pixel's numbers/ conversion of what the computer sees\n",
        "  for i in range(28):\n",
        "      for j in range(28):\n",
        "          print(str(x_train[im,i,j]+1000)[1:],end=' ')\n",
        "      print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset sizes:\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n",
            "Class: 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 050 117 094 038 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
            "000 044 121 000 056 106 000 029 042 051 053 057 060 063 062 060 059 058 054 048 045 044 046 013 000 054 004 000 \n",
            "000 116 016 000 089 115 059 177 145 154 151 148 147 153 155 159 160 164 174 171 171 154 162 157 004 151 025 000 \n",
            "028 092 000 000 068 204 206 206 198 196 194 189 187 181 181 182 183 183 185 186 185 185 185 194 198 181 001 000 \n",
            "073 040 000 000 013 195 215 210 215 215 216 214 214 216 216 214 213 214 215 215 215 215 214 207 229 168 000 000 \n",
            "071 016 000 000 000 187 226 205 210 212 213 209 210 213 213 212 210 210 210 209 210 210 214 208 227 172 051 000 \n",
            "074 010 000 000 000 183 215 206 213 212 213 210 213 213 213 213 212 213 213 213 212 212 213 209 232 150 112 000 \n",
            "076 011 000 000 039 234 203 214 208 216 215 213 215 214 214 213 213 213 213 212 213 212 212 196 227 207 191 000 \n",
            "072 015 000 000 054 196 213 210 210 213 213 210 213 213 213 212 212 212 213 213 213 213 216 205 233 161 196 082 \n",
            "062 032 000 030 024 197 222 208 212 216 214 214 215 214 215 216 213 210 214 214 213 212 213 203 227 156 137 000 \n",
            "019 098 000 093 024 227 224 216 205 205 204 205 207 209 210 210 206 205 203 201 199 198 198 208 223 191 112 000 \n",
            "000 090 039 000 000 206 229 239 238 234 233 232 232 232 230 226 225 223 223 222 220 217 222 217 206 223 164 000 \n",
            "000 000 152 067 000 163 240 221 239 233 226 221 220 220 215 214 213 215 217 217 216 218 214 208 209 203 190 000 \n",
            "002 000 000 222 153 181 241 239 242 239 235 229 224 223 221 204 206 203 207 208 212 214 213 214 217 176 085 094 \n",
            "000 002 000 000 205 242 197 209 225 224 235 233 225 226 217 210 208 206 205 203 200 198 209 205 185 108 076 050 \n",
            "000 000 004 000 157 231 206 206 213 209 215 215 210 222 232 231 227 227 226 227 225 229 205 177 234 000 000 000 \n",
            "001 000 001 000 252 250 232 255 240 242 232 231 222 233 198 110 141 146 150 144 136 135 104 106 001 000 006 000 \n",
            "000 001 002 000 065 128 162 176 191 205 204 201 191 205 038 000 000 000 000 000 000 000 000 000 000 005 002 000 \n",
            "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 \n",
            "Class: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAR2klEQVR4nO3dXWyVZbYH8P8SWloLKCBWPioF/IqfDBYiGTjhxDgyeIGj0QwXhJNMDnMxJjPJXBzjuYB4RU4OM5kLM7Fz1GFO5qiTzChcEA8cMgkOmlFU1OInIshHoUyItBT5KKxz0RdTse9adT/73e+G9f8lpO1effZ+unf/7N293ud9RFVBRJe/K8qeABHVBsNOFATDThQEw04UBMNOFMToWt6YiPCt/wqMGzfOrI8eXfnDeP78ebN+xRVpzwfW+P7+fnPsqVOnkm47KlWV4S5PCruILAHwGwCjAPyXqq5NuT4a3j333GPWJ02alFs7d+6cOfbkyZNmvaWlxax7/xk0Nzfn1l5//XVz7EcffWTW65nIsHn7Whkt74r/2xaRUQCeAvBDALcCWC4it1ZrYkRUXSmv0eYD2K2qe1T1DIAXACyrzrSIqNpSwj4NwP4hXx/ILvsGEVklIjtEZEfCbRFRosLfoFPVTgCdAN+gIypTyjP7QQBtQ76enl1GRHUoJexvArhRRGaKSCOAHwPYWJ1pEVG1VfwyXlUHROQxAP+Lwdbbs6q6q2ozG4bVzihz9Z7XfrrvvvvM+po1a8y613rr6urKrZ05c8Yc67XeGhoazPqYMWPM+oQJE3JrM2bMMMdu3Gg/dzz11FNm/bXXXsutnThxwhzr8R5z7/iFMiT9za6qmwBsqtJciKhAPFyWKAiGnSgIhp0oCIadKAiGnSgIhp0oCKllf7rIw2VHjRpl1r2lnt6SxOeeey63dscdd5hjjx07Zta9ddvt7e1m/fTp07k17/H1fu6UtfKA3W9uamoyx/b09Jh17zFtbGzMrXnnCHj44YfN+meffWbWveMTzp49a9ZT5K1n5zM7URAMO1EQDDtREAw7URAMO1EQDDtREJdU663IJa4vvviiWR87dmxu7fDhw+ZYb27eMtSlS5ea9e7u7tzawMCAOdabm9d681qe1vVPnTrVHLtpk72g0mtfWe2va6+91hzreeihh5LGF/m7zNYbUXAMO1EQDDtREAw7URAMO1EQDDtREAw7URA13bK5TFOmTDHrVh8dAI4fP55b85aJessdv/rqK7Pe19dn1q25e8tnvWWi3ty9Pv5VV12VW/OOL/BO99za2mrWrZ/NejwBYNGiRWZ9+vTpZv3AgQNmvQx8ZicKgmEnCoJhJwqCYScKgmEnCoJhJwqCYScK4pLqs6esAb7tttvMenNzs1m3tug9evSoOdY6pTHgb3vsnbZ47ty5ubXe3l5zrDc3r4/urXe/+uqrc2uvvvqqOXb8+PFm3TtGwFpr/+WXX5pjvcf0gQceMOtPP/20WS9ji/GksIvIXgB9AM4BGFDVjmpMioiqrxrP7P+sqv+owvUQUYH4NztREKlhVwCbReQtEVk13DeIyCoR2SEiOxJvi4gSpL6MX6iqB0XkWgBbROQjVd029BtUtRNAJ1DsXm9EZEt6ZlfVg9nHHgAvAZhfjUkRUfVVHHYRaRGRcRc+B/ADAF3VmhgRVVfKy/hWAC9lve/RAP5HVV+pyqxyWNv/epYsWWLWvXXbVl80dXvelpYWs75v3z6zPm3atNza5MmTzbGHDh0y695a/ZkzZ5r1Xbt2VXzbEyZMMOve/d7f359bu/76682x3nr3+++/36x7ffYyVBx2Vd0D4K4qzoWICsTWG1EQDDtREAw7URAMO1EQDDtREJfUls0WawkqYLeAAGD//v1m3Vqq6Z022GoBAenLTK3rX7BggTnWOtUz4LfePv/8c7P+7rvv5tas+xTwt4P2lrha9Ztvvtkc29PTY9bb29vN+iOPPGLWP/nkE7Oegls2EwXHsBMFwbATBcGwEwXBsBMFwbATBcGwEwVx2fTZOzrsE9uuXbvWrHvbIk+dOjW31tTUZI594403zLrH6ydbWx97y4Kt5bGA3+Pv7u4269bpoL25ebft9eGtXvgNN9xgjn3nnXfMundcx86dO836k08+adZTsM9OFBzDThQEw04UBMNOFATDThQEw04UBMNOFMRl02ffvn27Wbf65IDdqwaAcePG5dY6OzvNsbNnzzbrN910k1k/deqUWbekrIUH/B6/tybdWqvv/Vxjx44167t37zbr1tznzJljjt2zZ49Z905z7W03vWLFitxaV1fa9gvssxMFx7ATBcGwEwXBsBMFwbATBcGwEwXBsBMFkbJlc11Zvny5Wb/lllvM+p133mnWV69enVvbvHmzOXbdunVmfdKkSWa9t7fXrFvrwr3jKKzjB0bCW9dtnXe+ubnZHOv12b0e/wsvvJBbs/rcAHDy5Emz/vHHH5v1V16xdy9P7aVXwn1mF5FnRaRHRLqGXDZRRLaIyKfZR/sIAyIq3Uhexv8ewJKLLnscwFZVvRHA1uxrIqpjbthVdRuAYxddvAzA+uzz9QAerPK8iKjKKv2bvVVVL5x87DCA1rxvFJFVAFZVeDtEVCXJb9CpqloLXFS1E0AnUOxCGCKyVdp6OyIiUwAg+2hveUlEpas07BsBrMw+XwlgQ3WmQ0RFcdezi8jzABYDuAbAEQCrAbwM4E8ArgewD8Cjqnrxm3jDXVfIl/EHDx40695e4N6adOsx9MZ6vP3ZvXO/W+d2b2hoMMemnmvh3nvvza0tXrzYHLthw6X7/JW3nt39m11V845Wyb8niaju8HBZoiAYdqIgGHaiIBh2oiAYdqIgLptTSXvb93q8FlNKC2vv3r1m/ciRI2bdm5v1GHqPby0f/4t5bTuvNectDfZO4V0kb+lvymPm4amkiYJj2ImCYNiJgmDYiYJg2ImCYNiJgmDYiYK4bE4l7W0t7PH6oin6+vrMuneMQMrP5vXoPUX24b37fMyYMWb9+PHj1ZzON6Q+Jt4xBGXgMztREAw7URAMO1EQDDtREAw7URAMO1EQDDtREJdNn72eeX12r5/s9WytfnVqnzz1+APr9r1jAE6fPm3Wi+xl12OfPBWf2YmCYNiJgmDYiYJg2ImCYNiJgmDYiYJg2ImCYJ89U+S6bW9t9OjR9sPgrZ1O6YV7/WSv7vXKU9bTez9Xc3NzxdcdkftbIiLPikiPiHQNuWyNiBwUkZ3Zv6XFTpOIUo3kKeH3AJYMc/mvVXVO9m9TdadFRNXmhl1VtwE4VoO5EFGBUt6ge0xE3ste5k/I+yYRWSUiO0RkR8JtEVGiSsP+WwCzAcwB0A1gXd43qmqnqnaoakeFt0VEVVBR2FX1iKqeU9XzAH4HYH51p0VE1VZR2EVkypAvfwSgK+97iag+uH12EXkewGIA14jIAQCrASwWkTkAFMBeAD8tcI41kbIHuqepqcmse3u/e+u6i+yzpx5/YN2v3nV7xx9MnDjRrFvHN3jHLhT5+1AWN+yqunyYi58pYC5EVCAeLksUBMNOFATDThQEw04UBMNOFASXuNbArFmzzPqBAwfMemNjo1m3Wm8pp6EGit3yOfVU0m1tbWZ9xowZubU9e/aYY1N/7nrEZ3aiIBh2oiAYdqIgGHaiIBh2oiAYdqIgGHaiINhnz6T0VadPn27Wjx2zT+HnnWra29I5ZbmlN7bMU2x7t3348GGzvmjRotya12e/FJewevjMThQEw04UBMNOFATDThQEw04UBMNOFATDThQE++wZb923ZeHChWa9oaHBrPf395t1b825dVpk7/iBMk8l7Z1CO1VHR/4mROvXrzfHpvw+AP5jlnr9leAzO1EQDDtREAw7URAMO1EQDDtREAw7URAMO1EQ7LNXwd133500PnV74JS1+EXfdsp5471etNennzdvnlkvUj2uh3ef2UWkTUT+KiIfiMguEfl5dvlEEdkiIp9mHycUP10iqtRIXsYPAPilqt4K4B4APxORWwE8DmCrqt4IYGv2NRHVKTfsqtqtqm9nn/cB+BDANADLAFw45nA9gAeLmiQRpftOf7OLSDuA7wH4O4BWVe3OSocBtOaMWQVgVeVTJKJqGPG78SIyFsCfAfxCVXuH1nTw3Yhh35FQ1U5V7VDV/FUJRFS4EYVdRBowGPQ/qupfsouPiMiUrD4FQE8xUySianBfxstgf+QZAB+q6q+GlDYCWAlgbfZxQyEzrJGUVsntt99u1r0WkVdPOeVy6tbDRY73rttbGnzmzBmzftddd5n1FKktyzKM5G/27wNYAeB9EdmZXfYEBkP+JxH5CYB9AB4tZopEVA1u2FX1bwDy/hu7t7rTIaKi8HBZoiAYdqIgGHaiIBh2oiAYdqIgwixxLbIv2t7ebta9pZqjR9sPQ+rWxinKPJW095hZp9AG7C2dZ82aZY71tnROOb13WfjMThQEw04UBMNOFATDThQEw04UBMNOFATDThREmD57kX3RGTNmmPVDhw6Z9dRTKlu8n9tT5KmmvetOvW3r+IUFCxaYY70++6WIz+xEQTDsREEw7ERBMOxEQTDsREEw7ERBMOxEQYTps6dqbGzMrX3xxRfm2NRet8e6/qJ72SmKvl8s06ZNSxpfj+eF9/CZnSgIhp0oCIadKAiGnSgIhp0oCIadKAiGnSiIkezP3gbgDwBaASiATlX9jYisAfCvAI5m3/qEqm4qaqJla2try615530/ffq0WffWq589e9asW/3q1F52aj/ZGp+yTn8krOtvaWkp9Lbr0UgOqhkA8EtVfVtExgF4S0S2ZLVfq+p/Fjc9IqqWkezP3g2gO/u8T0Q+BJB2+BER1dx3eo0nIu0Avgfg79lFj4nIeyLyrIhMyBmzSkR2iMiOpJkSUZIRh11ExgL4M4BfqGovgN8CmA1gDgaf+dcNN05VO1W1Q1U7qjBfIqrQiMIuIg0YDPofVfUvAKCqR1T1nKqeB/A7APOLmyYRpXLDLoPLop4B8KGq/mrI5VOGfNuPAHRVf3pEVC0jeTf++wBWAHhfRHZmlz0BYLmIzMFgO24vgJ8WMsMq8ZZyeubNm5dbmzx5sjn2+PHjZv26666raE4XpLTeUu+XFF5bzzu9d3d3t1kfP358bm3u3Lnm2MvRSN6N/xuA4X4jLtueOtHliEfQEQXBsBMFwbATBcGwEwXBsBMFwbATBRHmVNIpWzIDwLZt23JrL7/8sjnW67P39/ebdW8p6MDAQMXX3dvba9a95bke6xTcV155pTm2qanJrFs/NwC0trbm1rZv326O9RS9PLcIfGYnCoJhJwqCYScKgmEnCoJhJwqCYScKgmEnCkJqufWsiBwFsG/IRdcA+EfNJvDd1Ovc6nVeAOdWqWrObYaqDnuChZqG/Vs3LrKjXs9NV69zq9d5AZxbpWo1N76MJwqCYScKouywd5Z8+5Z6nVu9zgvg3CpVk7mV+jc7EdVO2c/sRFQjDDtREKWEXUSWiMjHIrJbRB4vYw55RGSviLwvIjvL3p8u20OvR0S6hlw2UUS2iMin2cdh99graW5rRORgdt/tFJGlJc2tTUT+KiIfiMguEfl5dnmp950xr5rcbzX/m11ERgH4BMB9AA4AeBPAclX9oKYTySEiewF0qGrpB2CIyD8BOAHgD6p6e3bZfwA4pqprs/8oJ6jqv9XJ3NYAOFH2Nt7ZbkVThm4zDuBBAP+CEu87Y16Pogb3WxnP7PMB7FbVPap6BsALAJaVMI+6p6rbABy76OJlANZnn6/H4C9LzeXMrS6oareqvp193gfgwjbjpd53xrxqooywTwOwf8jXB1Bf+70rgM0i8paIrCp7MsNoVdUL+x4dBpB/7qVyuNt419JF24zXzX1XyfbnqfgG3bctVNW5AH4I4GfZy9W6pIN/g9VT73RE23jXyjDbjH+tzPuu0u3PU5UR9oMA2oZ8PT27rC6o6sHsYw+Al1B/W1EfubCDbvaxp+T5fK2etvEebptx1MF9V+b252WE/U0AN4rITBFpBPBjABtLmMe3iEhL9sYJRKQFwA9Qf1tRbwSwMvt8JYANJc7lG+plG++8bcZR8n1X+vbnqlrzfwCWYvAd+c8A/HsZc8iZ1ywA72b/dpU9NwDPY/Bl3VkMvrfxEwCTAGwF8CmA/wMwsY7m9t8A3gfwHgaDNaWkuS3E4Ev09wDszP4tLfu+M+ZVk/uNh8sSBcE36IiCYNiJgmDYiYJg2ImCYNiJgmDYiYJg2ImC+H+vbCpxSi0/RQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "000 000 000 000 000 000 000 000 000 000 069 088 085 075 086 088 097 040 000 000 000 000 000 000 001 000 000 000 \n",
            "000 000 001 000 000 000 000 002 071 199 255 211 205 196 200 207 224 255 177 070 012 000 000 002 000 000 000 000 \n",
            "000 000 000 003 000 001 160 205 187 179 211 204 203 204 208 208 206 214 192 189 195 208 035 000 005 000 000 000 \n",
            "000 000 001 000 000 169 181 157 156 150 224 199 195 194 198 201 200 226 152 148 152 174 174 000 000 001 000 000 \n",
            "000 000 001 000 025 181 166 158 162 147 212 211 203 200 205 201 215 220 140 164 160 159 220 028 000 001 000 000 \n",
            "000 000 002 000 068 190 183 162 168 154 176 226 197 203 201 205 231 170 154 160 164 147 199 103 000 000 000 000 \n",
            "000 000 000 000 140 195 189 167 163 165 145 203 218 192 193 226 188 144 161 166 155 177 184 174 000 000 000 000 \n",
            "000 000 000 002 215 186 202 174 164 169 165 154 211 226 228 194 147 164 166 164 160 199 177 209 038 000 000 000 \n",
            "000 000 000 053 188 175 201 209 155 155 152 146 144 171 167 142 156 154 150 153 185 221 172 174 126 000 000 000 \n",
            "000 000 000 197 223 217 230 128 164 201 193 193 189 178 175 191 197 189 201 165 162 210 176 193 207 045 000 000 \n",
            "000 000 000 030 070 116 244 058 199 220 206 204 203 202 202 204 205 206 218 181 093 255 200 161 089 000 000 000 \n",
            "000 000 000 000 000 000 000 000 229 207 203 202 198 198 199 197 200 205 204 204 015 079 000 000 000 000 000 000 \n",
            "000 000 000 003 003 004 000 000 224 201 202 201 200 199 199 199 199 197 202 221 000 000 000 000 002 001 000 000 \n",
            "000 000 000 000 000 002 000 000 211 204 201 201 201 200 199 199 199 199 209 206 000 000 003 000 000 000 000 000 \n",
            "000 000 000 000 000 002 000 000 198 205 199 201 200 200 201 201 200 201 202 200 000 000 001 000 000 000 000 000 \n",
            "000 000 000 000 000 001 000 000 201 209 202 204 204 202 200 201 201 201 204 212 000 000 001 000 000 000 000 000 \n",
            "000 000 000 000 000 002 000 000 209 205 196 197 197 195 194 194 195 194 198 222 003 000 002 000 000 000 000 000 \n",
            "000 000 000 000 000 002 000 000 243 215 212 213 212 213 214 214 213 214 207 251 034 000 003 000 000 000 000 000 \n",
            "000 000 000 000 000 003 000 028 225 218 222 221 221 220 219 219 219 222 213 228 095 000 002 000 000 000 000 000 \n",
            "000 000 000 000 000 001 000 088 230 214 220 217 218 216 215 215 216 215 213 227 147 000 000 000 002 000 000 000 \n",
            "000 000 000 000 000 001 000 139 230 215 219 218 218 217 215 216 215 216 211 223 200 000 000 000 001 000 000 000 \n",
            "000 000 000 000 000 000 000 183 226 211 218 217 218 217 216 216 216 217 216 217 247 000 000 001 000 000 000 000 \n",
            "000 000 000 000 001 000 000 215 224 215 221 220 220 220 219 219 220 216 217 214 223 034 000 003 000 000 000 000 \n",
            "000 000 000 000 003 000 000 246 220 216 219 219 221 221 221 220 221 217 218 213 227 091 000 003 000 000 000 000 \n",
            "000 000 000 000 003 000 006 216 218 216 219 221 222 223 222 221 221 219 219 213 228 118 000 002 000 000 000 000 \n",
            "000 000 000 000 003 000 035 220 213 211 212 213 215 215 214 214 213 211 211 211 225 129 000 002 000 000 000 000 \n",
            "000 000 000 000 004 000 088 241 226 250 250 252 254 255 255 255 255 254 251 226 240 180 000 002 000 000 000 000 \n",
            "000 000 000 000 001 000 026 161 146 135 133 129 118 104 097 098 103 114 121 117 140 081 000 000 000 000 000 000 \n",
            "Class: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "000 000 000 000 000 000 000 000 000 000 000 177 209 191 191 211 159 000 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 000 223 231 231 231 236 219 000 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 099 235 218 221 224 222 239 081 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 128 235 219 220 224 222 239 120 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 139 229 219 220 222 221 239 124 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 152 226 218 220 221 220 236 136 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 155 228 217 219 220 219 236 137 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 137 231 216 220 219 217 238 123 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 111 232 216 222 218 215 236 106 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 091 233 216 220 219 215 237 081 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 094 233 216 222 221 214 236 082 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 098 235 218 224 222 213 236 081 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 098 235 219 227 223 213 236 092 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 101 234 219 230 225 213 237 095 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 106 234 220 232 227 214 237 092 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 110 235 221 234 228 215 238 102 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 116 233 226 228 223 218 238 109 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 121 230 235 184 188 226 237 106 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 124 230 241 145 157 231 237 112 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 127 229 244 127 144 235 237 118 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 130 229 245 100 124 238 236 118 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 134 229 247 083 103 240 238 123 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 146 230 249 065 085 243 237 127 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 167 229 250 044 075 242 236 147 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 186 227 251 061 084 245 233 170 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 207 224 248 092 114 244 232 191 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 226 232 255 130 154 250 238 209 000 000 000 000 000 000 000 000 000 000 \n",
            "000 000 000 000 000 000 000 000 000 000 094 204 232 014 044 212 202 079 000 000 000 000 000 000 000 000 000 000 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLEWoYaxZBbh"
      },
      "source": [
        "**Part 2 out of 2 for Exercise 2.** Evaluate the accuracy of 3-nearest neighbor on Fashion-MNIST\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAaEgPksBzAo",
        "outputId": "13cf70a7-7af1-48e3-be61-830a08d79665"
      },
      "source": [
        "#Part 2 out of 2 for Exercise 2. Evaluate the accuracy of 3-nearest neighbor on Fashion-MNIST\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "#change the same 3-D array format given into 2-D for the knn\n",
        "x_train = np.float32(x_train/255).reshape(x_train.shape[0],-1)\n",
        "x_test = np.float32(x_test/255).reshape(x_test.shape[0],-1)\n",
        "\n",
        "# Same as before we going to have to reduce the size of the array for the knn algorithm \n",
        "# by 1/5\n",
        "\n",
        "step = 5\n",
        "x_train = x_train[::step] \n",
        "y_train = y_train[::step] \n",
        "print(y_train)\n",
        "x_test = x_test[::step]\n",
        "y_test = y_test[::step]\n",
        "\n",
        "def distance(p,q): #Euclidean\n",
        "    return np.sqrt(np.sum(np.square(p-q))) \n",
        "\n",
        "def most_common(labels):\n",
        "    count = np.zeros(np.amax(labels)+1,dtype=np.int32)\n",
        "    for c in labels:\n",
        "        count[c] +=1\n",
        "    return np.argmax(count)\n",
        "\n",
        "def accuracy(p,y):\n",
        "    return np.mean(p==y)\n",
        "\n",
        "def knn(x_train, y_train, x_test, k):\n",
        "    pred = np.zeros(x_test.shape[0],dtype=int)\n",
        "    d = np.zeros(x_train.shape[0],dtype=np.float32)\n",
        "\n",
        "    for i in range(x_test.shape[0]):\n",
        "        for j in range(x_train.shape[0]):\n",
        "            d[j] = distance(x_test[i],x_train[j]) \n",
        "        neighbors = np.argsort(d)[:k]\n",
        "        pred[i] = most_common(y_train[neighbors])\n",
        "    return pred\n",
        "\n",
        "\n",
        "import time\n",
        "m = 100\n",
        "start = time.time()\n",
        "pred = knn(x_train, y_train, x_test[:m], 3)\n",
        "elapsed_time = time.time() - start\n",
        "print('Test set size =',n)\n",
        "print('Accuracy = {:.4f}'.format(accuracy(pred,y_test[:n])))\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))\n",
        "\n",
        "n = 1000\n",
        "start = time.time()\n",
        "pred = knn(x_train, y_train, x_test[:n], 3)\n",
        "elapsed_time = time.time() - start\n",
        "print('Test set size =',n)\n",
        "print('Accuracy = {:.4f}'.format(accuracy(pred,y_test[:n])))\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "[9 2 0 ... 0 4 5]\n",
            "Test set size = 1000\n",
            "Accuracy = 0.0000\n",
            "Elapsed time = 13.9300 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set size = 1000\n",
            "Accuracy = 0.8300\n",
            "Elapsed time = 138.0055 secs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPgMK2NHeI9M"
      },
      "source": [
        "### Exercise 2 analysis: \n",
        "Compared to using the same method on the MNIST dataset with numbers from below :\n",
        "\n",
        "Test set size = 100\n",
        "Accuracy = 0.9100\n",
        "Elapsed time = 13.9099 secs\n",
        "\n",
        "test set size = 1000\n",
        "accuracy\n",
        "elapsed time = \n",
        "\n",
        "MNIST dataset using Fashion dataset has a decreased accurracy of about .88 but an improved time completion of about 1 second versus its MNIST number dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcgPC6YsFm-o"
      },
      "source": [
        "# **Exercise 3.**\n",
        "We can speed up the computation significantly (at the cost of lower accuracy) by generating a new training set containing only ONE example of every class and applying 1-nearest neighbor.\n",
        "\n",
        "Usually we find the mean (average) example for every class and use that as the representative for that class\n",
        "\n",
        "Thus you should generate a new training dataset of size 10 from x_train. The first example in your dataset should be the mean of all examples of class 0 in x_train, the second example should be the mean of all examples of class 1 in x_train, and so on.\n",
        "\n",
        "Add all the value of the numbers than divided by the total number of numbers you  add example 1,2,3,3,9,10\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ynxxH2WHCPX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "bcff5a75-4971-4556-bb24-5294821e7ebc"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = np.float32(x_train/255).reshape(x_train.shape[0],-1)\n",
        "x_test = np.float32(x_test/255).reshape(x_test.shape[0],-1)\n",
        "\n",
        "\n",
        "print(x_train.shape[0])\n",
        "print(x_train.shape[1])\n",
        "\n",
        "\n",
        "step = 5\n",
        "\n",
        "x_train = x_train[::step] \n",
        "y_train = y_train[::step] \n",
        "x_test = x_test[::step]\n",
        "y_test = y_test[::step]\n",
        "\n",
        "for i in range(len(np.amax(y_train))\n",
        "\n",
        "np.mean()\n",
        "\n",
        "\n",
        "m_yset = np.array(y_train)\n",
        "m_xset = np.array( ,np.amax()+1)) #10, 728\n",
        "m_yset = np.array()               #10\n",
        "print(m_xset)\n",
        "print(m_yset)\n",
        "\n",
        " \n",
        " \n",
        "def distance(p,q): #Euclidean\n",
        "    return np.sqrt(np.sum(np.square(p-q))) \n",
        "\n",
        " \n",
        "def most_common(labels):\n",
        "    count = np.zeros(np.amax(labels)+1,dtype=np.int32)\n",
        "    for c in labels:\n",
        "        count[c] +=1\n",
        "    return np.argmax(count)\n",
        "\n",
        "def accuracy(p,y):\n",
        "    return np.mean(p==y)\n",
        "\n",
        "def knn(x_train, y_train, x_test, k):\n",
        "    pred = np.zeros(x_test.shape[0],dtype=int)\n",
        "    d = np.zeros(x_train.shape[0],dtype=np.float32)\n",
        "    for i in range(x_test.shape[0]):\n",
        "        for j in range(x_train.shape[0]):\n",
        "            d[j] = distance(x_test[i],x_train[j]) \n",
        "        neighbors = np.argsort(d)[:k]\n",
        "        pred[i] = most_common(y_train[neighbors])\n",
        "    return pred\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "#test1 \n",
        "n = 1000\n",
        "start = time.time()\n",
        "pred = knn(x_train, y_train, x_test[:n], 1)\n",
        "elapsed_time = time.time() - start\n",
        "print('Test set size =',n)\n",
        "print('Accuracy = {:.4f}'.format(accuracy(pred,y_test[:n])))\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))\n",
        "\n",
        "\n",
        "#test2 \n",
        "n = 100\n",
        "start = time.time()\n",
        "pred = knn(x_train, y_train, x_test[:n], 3)\n",
        "elapsed_time = time.time() - start\n",
        "print('Test set size =',n)\n",
        "print('Accuracy = {:.4f}'.format(accuracy(pred,y_test[:n])))\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))\n",
        "\n",
        "#test1 of set of mean of 10 images\n",
        "n = 1\n",
        "start = time.time()\n",
        "pred = knn(x_train, y_train, x_test[:n], 1)\n",
        "elapsed_time = time.time() - start\n",
        "print('Test set size =',n)\n",
        "print('Accuracy = {:.4f}'.format(accuracy(pred,y_test[:n])))\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "784\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f17ab8d103bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mm_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.int64' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LtRr7kT6ua0"
      },
      "source": [
        "# Exercise 3 analysis: \n",
        "\n",
        "The computational time did indeed speed up from just using just 10 images that each represented the image nearest or the mean the accuracy did go down when compared to using . "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxgLkJBCFnCL"
      },
      "source": [
        "## **Exercise 4.** Modify the knn function to also return an array C containing the number of neighbors of each test example that belong to the class that was predicted for that test example.\n",
        "\n",
        "For example, if the k-nearest neighbors of x_test[i] belong to classes [7,3,7], pred[i] is 7 and C[i] is 2, since 2 of the neighbors belong to the class predicted for that example. Clearly, C must be an integer between 1 and k.\n",
        "\n",
        "Use the function to evaluate the accuracy of the classier for cases where all the neighbors belong to the same class and for all other cases. We expect accuracy to be higher when all neighbors belong to the same class; find out if this assumption is correct. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbjcOR0rHDOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3874b5c2-c3e0-414e-ff3c-de801b44c3be"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = np.float32(x_train/255).reshape(x_train.shape[0],-1)\n",
        "x_test = np.float32(x_test/255).reshape(x_test.shape[0],-1)\n",
        "\n",
        "step = 5\n",
        "x_train = x_train[::step] \n",
        "y_train = y_train[::step] \n",
        "x_test = x_test[::step]\n",
        "y_test = y_test[::step]\n",
        "\n",
        "def distance(p,q): #Euclidean\n",
        "    return np.sqrt(np.sum(np.square(p-q))) \n",
        " \n",
        "def most_common(labels):\n",
        "    count = np.zeros(np.amax(labels)+1,dtype=np.int32)\n",
        "    for c in labels:\n",
        "        count[c] +=1\n",
        "    return np.argmax(count)\n",
        "\n",
        "def accuracy(p,y):\n",
        "    return np.mean(p==y)\n",
        "\n",
        "def knn_(x_train, y_train, x_test, k):\n",
        "    # Returns predicted class for examples in x_test\n",
        "    predict = np.zeros(x_test.shape[0],dtype=int)\n",
        "    c = np.zeros(x_test.shape[0],dtype=int)\n",
        "    d = np.zeros(x_train.shape[0],dtype=np.float32)\n",
        "    for i in range(x_test.shape[0]):\n",
        "        for j in range(x_train.shape[0]):\n",
        "            d[j] = distance(x_test[i],x_train[j]) \n",
        "        neighbors = np.argsort(d)[:k]\n",
        "        y_c = np.bincount(y_train[neighbors])\n",
        "        nkk = np.amax()\n",
        "    \n",
        "        c[i] = nkk\n",
        "        pred[i] = most_common(y_train[neighbors])\n",
        "    return predict, freqency\n",
        "\n",
        "pred2, c2 = knn_mod(x_train, y_train, x_test[:500], 7)\n",
        "\n",
        "\n",
        "print('Accuracy = {:.4f}'.format(accuracy(pred,y_test[:1000])))\n",
        "print(pred2,c2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 1.0000\n",
            "[7 1 0 5 9 0 3 2 1 5] [5 5 5 5 5 5 5 5 5 5]\n",
            "\n",
            "\n",
            "Accuracy = 0.9340\n",
            "[7 1 0 5 9 0 3 2 1 5 6 0 7 4 7 7 7 4 3 4 6 9 8 9 5 9 6 1 6 1 9 5 4 5 4 7 1\n",
            " 9 1 1 3 3 4 0 7 2 3 9 5 3 4 7 8 1 3 4 2 2 8 4 1 0 3 9 1 4 1 3 3 1 1 8 4 0\n",
            " 7 5 0 1 2 5 2 4 7 7 4 4 1 8 0 0 3 1 9 8 8 4 1 0 0 0 3 3 7 3 8 0 9 4 5 0 7\n",
            " 4 9 4 5 9 8 7 3 3 6 7 4 1 0 6 9 1 1 5 6 8 4 6 4 1 6 8 2 1 1 7 5 2 5 1 7 1\n",
            " 9 1 0 1 9 4 4 2 3 5 1 3 8 8 7 3 6 7 4 1 1 0 1 3 6 3 6 2 7 6 3 0 1 2 4 8 1\n",
            " 3 7 5 6 2 7 5 7 0 5 2 2 2 7 2 9 9 4 4 3 1 1 6 1 9 0 7 4 2 5 1 4 6 9 3 7 9\n",
            " 7 5 8 8 9 5 4 4 3 2 4 9 8 7 1 8 5 0 8 3 2 3 0 8 4 5 1 2 6 9 1 3 9 4 1 5 3\n",
            " 1 4 1 3 3 8 5 4 2 5 2 1 7 1 2 5 2 9 9 0 2 6 5 2 8 6 8 1 9 4 0 6 9 5 1 8 6\n",
            " 3 2 3 3 1 7 5 1 7 5 7 0 7 9 5 1 8 0 0 4 4 2 0 7 3 3 0 3 2 4 1 5 9 9 0 9 7\n",
            " 4 5 8 4 6 3 9 0 7 7 1 4 6 3 4 8 9 7 5 1 3 7 0 1 1 7 2 6 7 5 4 1 9 1 1 3 3\n",
            " 7 7 5 4 0 7 6 1 2 2 1 6 5 2 4 7 2 7 5 1 7 2 8 2 5 7 4 4 6 0 6 4 1 1 3 3 5\n",
            " 5 5 3 8 2 0 8 4 3 3 2 4 7 5 3 2 7 4 9 9 1 6 4 6 0 6 4 6 1 5 5 0 7 2 4 6 6\n",
            " 7 8 3 1 7 1 9 3 2 4 7 7 3 7 7 0 3 3 9 1 9 1 4 1 4 7 2 1 6 7 0 4 9 0 2 0 5\n",
            " 3 0 2 9 8 8 0 4 5 3 0 5 6 8 2 7 0 7 2] [5 5 5 5 5 5 5 5 5 5 5 5 5 3 5 5 4 5 5 5 5 5 4 4 5 5 5 5 5 5 5 5 5 5 3 4 5\n",
            " 5 5 3 5 5 5 5 5 5 5 5 5 5 3 5 5 5 5 5 5 5 4 5 5 5 5 5 2 3 5 4 3 5 5 5 4 5\n",
            " 5 5 5 5 5 4 5 5 5 4 4 5 5 4 5 5 5 5 3 5 4 5 5 5 5 4 5 5 5 3 5 5 5 5 5 5 5\n",
            " 5 4 2 5 5 5 5 5 5 5 5 3 5 5 5 5 5 5 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 3 5 5 4 5 5 5 4 3 5 5 5 5 5 4 5 5 5 5 5 5 5 5 5 5 5 4 5 5 5 5 5 5\n",
            " 5 3 5 5 5 5 4 4 4 5 3 5 5 2 4 5 5 5 5 5 5 5 5 5 5 3 4 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 4 5 4 5 5 4 5 5 3 5 5 5 5 5 5 5 5 5 5 5 5 4 4 3 5 5 4\n",
            " 5 5 5 5 5 5 2 5 5 5 5 5 4 5 5 5 5 4 5 5 4 5 5 4 3 5 2 5 5 5 5 5 5 5 4 4 5\n",
            " 5 5 5 3 5 5 5 5 5 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 3 5 5 4 5\n",
            " 5 4 4 4 5 5 5 5 5 5 5 5 5 4 4 4 5 3 4 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5\n",
            " 2 3 4 3 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 3 5 3 4 5 5 5 5 5 5 5 5 5 5 5 4\n",
            " 3 5 5 5 5 5 5 2 5 5 5 4 5 5 5 5 5 5 3 5 5 5 5 5 5 5 5 5 5 5 3 5 5 3 5 5 3\n",
            " 5 3 5 5 5 5 5 4 5 5 5 5 5 5 5 5 5 5 5 5 3 4 5 5 5 3 5 5 5 5 5 5 5 5 5 3 5\n",
            " 5 5 5 5 3 3 5 5 4 5 5 4 5 5 5 5 5 5 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpU1-yN462zK"
      },
      "source": [
        "# Exercise 4 analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osCAPVyCFnFZ"
      },
      "source": [
        "## **Exercise 5**. Use the sklearn implementation of k-nearest neighbors to classify the MNIST and Fashion-MNIST datasets.\n",
        "\n",
        "See https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html for documentation.\n",
        "\n",
        "Display accuracies and running times using default parameters.\n",
        "\n",
        "Try to improve performance, either accuracy or running time, but using different parameters. In particular, answer the following questions:\n",
        "\n",
        "Does weighted or unweighted k-nn result in higher accuracy?\n",
        "What are the effects of the choice of k on the algorithms accuracy and running times?\n",
        "Which algorithm to compute the nearest neighbors (ball tree, kd tree, or brute force) yields the best results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeNKATZMPM6x"
      },
      "source": [
        "## **Part 1 of 2:**Using MNIST regular dataset \n",
        "Display accuracies and running times using default parameters.\n",
        "Try to improve performance, either accuracy or running time, but using different parameters. In particular, answer the following questions:\n",
        "\n",
        "*   Does weighted or unweighted k-nn result in higher accuracy?\n",
        "*   What are the effects of the choice of k on the algorithms accuracy and running times?\n",
        "*   Which algorithm to compute the nearest neighbors (ball tree, kd tree, or brute force) yields the best results?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayDugJg2rbCg",
        "outputId": "b5ab9aa2-3cda-4ac6-bb78-0d22a466d091"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = np.float32(x_train/255).reshape(x_train.shape[0],-1)\n",
        "x_test = np.float32(x_test/255).reshape(x_test.shape[0],-1)\n",
        "\n",
        "step = 5\n",
        "x_train = x_train[::step]\n",
        "y_train = y_train[::step]\n",
        "x_test = x_test[::step]\n",
        "y_test = y_test[::step]\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "#default\n",
        "predicted = KNeighborsClassifier().fit(x_train, y_train)\n",
        "accuracy = predicted.score(x_test,y_test)\n",
        "print(\"MNIST with default: \", accuracy)\n",
        "\n",
        "elapsed_time = time.time() - start\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST with default:  0.953\n",
            "Elapsed time = 46.0941 secs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB9v2VMKownx",
        "outputId": "1a299127-1e96-46b6-c989-02cc8829ab30"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = np.float32(x_train/255).reshape(x_train.shape[0],-1)\n",
        "x_test = np.float32(x_test/255).reshape(x_test.shape[0],-1)\n",
        "\n",
        "step = 5\n",
        "x_train = x_train[::step]\n",
        "y_train = y_train[::step]\n",
        "x_test = x_test[::step]\n",
        "y_test = y_test[::step]\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "sk_classifier = KNeighborsClassifier(n_neighbors=3).fit(x_train, y_train)\n",
        "sk_accuracy = sk_classifier.score(x_test,y_test)\n",
        "print(\"MNIST unweighted Accuracy: \", sk_accuracy)\n",
        "\n",
        "elapsed_time = time.time() - start\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "sk_classifier = KNeighborsClassifier(n_neighbors=3, weights = 'distance').fit(x_train, y_train)\n",
        "sk_accuracy = sk_classifier.score(x_test,y_test)\n",
        "print(\"MNIST weighted Accuracy: \", sk_accuracy)\n",
        "\n",
        "elapsed_time = time.time() - start\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "sk_classifier = KNeighborsClassifier(n_neighbors=3,algorithm='ball_tree').fit(x_train, y_train)\n",
        "sk_accuracy = sk_classifier.score(x_test,y_test)\n",
        "print(\"MNIST  balltree Accuracy: \", sk_accuracy)\n",
        "elapsed_time = time.time() - start\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "#kdtree\n",
        "sk_classifier = KNeighborsClassifier(n_neighbors=3,algorithm='kd_tree').fit(x_train, y_train)\n",
        "sk_accuracy = sk_classifier.score(x_test,y_test)\n",
        "print(\"MNIST unweighted kdtree Accuracy: \", sk_accuracy)\n",
        "elapsed_time = time.time() - start\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "#brute-force\n",
        "classifier = KNeighborsClassifier(n_neighbors=3,algorithm='brute').fit(x_train, y_train)\n",
        "sk_accuracy = sk_classifier.score(x_test,y_test)\n",
        "print(\"MNIST unweighted brute Accuracy: \", sk_accuracy)\n",
        "elapsed_time = time.time() - start\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST unweighted Accuracy:  0.95\n",
            "Elapsed time = 47.5879 secs\n",
            "\n",
            "\n",
            "MNIST weighted Accuracy:  0.952\n",
            "Elapsed time = 47.2756 secs\n",
            "MNIST unweighted balltree Accuracy:  0.95\n",
            "Elapsed time = 38.5722 secs\n",
            "MNIST unweighted kdtree Accuracy:  0.95\n",
            "Elapsed time = 47.2219 secs\n",
            "MNIST unweighted brute Accuracy:  0.95\n",
            "Elapsed time = 1.9645 secs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmaf7-geHD8-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea594ea-63b3-411d-bcf5-96010556d512"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST Accuracy:\n",
            "Test set size = 20\n",
            "Accuracy = 0.9530\n",
            "Elapsed time = 41.5447 secs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPQ8_IDxyYw_"
      },
      "source": [
        "## **Part 2 of 2:**Using MNIST Fashion dataset \n",
        "Display accuracies and running times using default parameters. Try to improve performance, either accuracy or running time, but using different parameters. In particular, answer the following questions:\n",
        "\n",
        "Does weighted or unweighted k-nn result in higher accuracy?\n",
        "What are the effects of the choice of k on the algorithms accuracy and running times?\n",
        "Which algorithm to compute the nearest neighbors (ball tree, kd tree, or brute force) yields the best results?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv3-avh0FV-g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf223c91-148b-42eb-da8e-10760ec60ec6"
      },
      "source": [
        "#Fashion-MNIST dataset\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "test = y_test[::step]\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=5).fit(x_train, y_train)\n",
        "accuracy = sk_classifier.score(x_test,y_test)\n",
        "print(\"MNIST fashion unweighted Accuracy: \", accuracy)\n",
        "\n",
        "elapsed_time = time.time() - start\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=5, weights = 'distance').fit(x_train, y_train)\n",
        "accuracy = sclassifier.score(x_test,y_test)\n",
        "print(\"MNIST fashion weighted Accuracy: \", accuracy)\n",
        "\n",
        "elapsed_time = time.time() - start\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "classifier = KNeighborsClassifier(n_neighbors=5,algorithm='ball_tree').fit(x_train, y_train)\n",
        "accuracy = sk_classifier.score(x_test,y_test)\n",
        "print(\"MNIST fashion balltree Accuracy: \", accuracy)\n",
        "elapsed_time = time.time() - start\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "classifier = KNeighborsClassifier(n_neighbors=5,algorithm='kd_tree').fit(x_train, y_train)\n",
        "accuracy = classifier.score(x_test,y_test)\n",
        "print(\"MNIST fashion unweighted kdtree Accuracy: \", accuracy)\n",
        "elapsed_time = time.time() - start\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "#brute-force\n",
        "classifier = KNeighborsClassifier(n_neighbors=5,algorithm='brute').fit(x_train, y_train)\n",
        "sk_accuracy = sk_classifier.score(x_test,y_test)\n",
        "print(\"MNIST fashin brute Accuracy: \", accuracy)\n",
        "elapsed_time = time.time() - start\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))\n",
        "\n",
        "x_train = np.float32(x_train/255).reshape(x_train.shape[0],-1)\n",
        "x_test = np.float32(x_test/255).reshape(x_test.shape[0],-1)\n",
        "\n",
        "\n",
        "step = 5\n",
        "x_train = x_train[::step] \n",
        "y_train = y_train[::step] \n",
        "x_test = x_test[::step]\n",
        "y_test = y_test[::step]\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "n = 100\n",
        "start = time.time()\n",
        "classifier = KNeighborsClassifier(n_neighbors=5).fit(x_train, y_train)\n",
        "accuracy = sclassifier.score(x_test,y_test)\n",
        "\n",
        "elapsed_time = time.time() - start\n",
        "print(\"Fashion MNIST Accuracy:\")\n",
        "print('Test set size =',n)\n",
        "print('Accuracy = {:.4f}'.format(sk_accuracy))\n",
        "print('Elapsed time = {:.4f} secs'.format(elapsed_time))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "Fashion MNIST Accuracy:\n",
            "Test set size = 100\n",
            "Accuracy = 0.8230\n",
            "Elapsed time = 41.2764 secs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn2dOoT27B69"
      },
      "source": [
        "# Exercise 5 analysis\n",
        "##Part 1 of 2 with regular MNSET \n",
        "It is easy to see brute force takes the least time\n"
      ]
    }
  ]
}